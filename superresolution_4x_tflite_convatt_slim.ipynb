{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "superresolution_4x_tflite_convatt_slim.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y52zwvlpHvCC"
      },
      "source": [
        "## superresolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s-U33BDYHvCF"
      },
      "source": [
        "### options\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bDQFzxuJHvCH",
        "colab": {}
      },
      "source": [
        "separator_epochs = 50\n",
        "epochs = 10 #Number of epochs to train\n",
        "scale = 4 #How much should we upscale images\n",
        "steps_per_epoch = 1000\n",
        "channels = 3 #channels of low resolution image\n",
        "batch_size = 64 #what batch-size should we use (decrease if you encounter video memory errors)\n",
        "height_lr = 128 #height of low resolution image\n",
        "width_lr = height_lr #width of low resolution image\n",
        "learning_rate = 0.0001 #learning rate\n",
        "logging_steps = steps_per_epoch // 5 #how often to update the training log\n",
        "separator_weight_file = 'sr_4x_separator_weights_convatt' #name of weight file\n",
        "generator_weight_file = 'sr_4x_generator_weights_convatt_slim' #name of weight file\n",
        "generator_optimizer_weight_file = 'sr_4x_generator_optimizer_weights_convatt_slim' #name of weight file\n",
        "batch_file = 'batch'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GzyzlkF3HvCL"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v78MsA4CHvCM",
        "colab": {}
      },
      "source": [
        "import os\n",
        "%cd /content\n",
        "!git clone https://github.com/BenjaminWegener/superresolution #download Dataset\n",
        "%cd superresolution\n",
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "!pip install tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from math import isnan\n",
        "import random\n",
        "import dill\n",
        "import time\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "from contextlib import contextmanager\n",
        "import sys\n",
        "@contextmanager\n",
        "def silence_stdout():\n",
        "    new_target = open(os.devnull, \"w\")\n",
        "    old_target = sys.stdout\n",
        "    sys.stdout = new_target\n",
        "    try:\n",
        "        yield new_target\n",
        "    finally:\n",
        "        sys.stdout = old_target   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WyQf_dwWHvCR"
      },
      "source": [
        "### functions for image visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ygs-7DxwHvCS",
        "colab": {}
      },
      "source": [
        "def show(tensors, normalize = False):\n",
        "    plt.rcParams['figure.figsize'] = [20, 10]\n",
        "    fig = plt.figure()\n",
        "    for i in range(len(tensors)):\n",
        "        cmap = 'gray'\n",
        "        try:\n",
        "            tensors[i] = np.squeeze(tensors[i], axis = 0)\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            tensors[i] = np.squeeze(tensors[i], axis = 2)\n",
        "        except:\n",
        "            pass\n",
        "        try:    \n",
        "            depth = tensors[i].shape[2]\n",
        "            cmap = None\n",
        "        except:\n",
        "            pass\n",
        "        if normalize:\n",
        "            tensors[i] = tensors[i] * 255\n",
        "        tensors[i] = np.clip(tensors[i], 0, 255)\n",
        "        fig.add_subplot(1, len(tensors), i + 1)\n",
        "        plt.imshow(tensors[i].astype(np.uint8), cmap = cmap, interpolation = 'spline36')\n",
        "        #plt.imshow(tensors[i].astype(np.uint8).squeeze(axis=2), cmap='gray', interpolation = 'spline36')\n",
        "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYBDslhEySJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show image in actual size https://stackoverflow.com/a/42314798/\n",
        "def display_image_in_actual_size(im_data):\n",
        "    try:\n",
        "        im_data = np.squeeze(im_data, axis = 0)\n",
        "    except:\n",
        "        pass \n",
        "    im_data = np.clip(im_data, 0, 255)\n",
        "    dpi = 100\n",
        "    print(im_data.shape)\n",
        "    height = im_data.shape[0]\n",
        "    width = im_data.shape[1]\n",
        "    figsize = width / float(dpi), height / float(dpi)\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "    ax.axis('off')\n",
        "    ax.imshow(im_data.astype(np.uint8), interpolation = 'spline36')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA3TToBjTLTd",
        "colab_type": "text"
      },
      "source": [
        "###initialize tpu backend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erR3p75VTPt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnsPysNsB_kM",
        "colab_type": "text"
      },
      "source": [
        "###dataset function separator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTQkvhEHCDRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# return batch of augmented train and target images with quantity n_samples\n",
        "def get_batch_separator(n_samples, height, width):\n",
        "    # define a ImageGenerator instance from keras with augmentations\n",
        "    image_gen = ImageDataGenerator(rotation_range = 359,\n",
        "                           width_shift_range = 2,\n",
        "                           height_shift_range = 2,\n",
        "                           zoom_range = [0.25, 0.8],\n",
        "                           shear_range = 0.1,\n",
        "                           horizontal_flip = True,\n",
        "                           vertical_flip = True,\n",
        "                           fill_mode = 'reflect',\n",
        "                           data_format = 'channels_last',\n",
        "                           interpolation_order = 5,\n",
        "                           brightness_range = [0.5, 1.5])\n",
        "    #seed for random augmentations\n",
        "    random_seed = int(random.random() * 100000)\n",
        "    #generate augmented images\n",
        "    with silence_stdout():\n",
        "        y_train = image_gen.flow_from_directory('.', \n",
        "                                                target_size = (height * scale, width * scale), \n",
        "                                                batch_size = n_samples, \n",
        "                                                class_mode = None,\n",
        "                                                interpolation = 'lanczos', \n",
        "                                                seed = random_seed)\n",
        "        y_train = y_train.__getitem__(0).copy() #fix for 'array doesn't own its data'\n",
        "        x_train = np.empty((len(y_train), height, width, 3))\n",
        "    for i in range(n_samples):\n",
        "        x_train[i] = resize(y_train[i], (height, width, 3), order = 5)\n",
        "    \n",
        "    z_train = np.dot(y_train[...,:3], [0.33, 0.33, 0.33])\n",
        "    return x_train, y_train, z_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ceGjQHDCbSi",
        "colab_type": "text"
      },
      "source": [
        "###build separator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWHXrkbICeTu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_separator():\n",
        "  inputs = Input(shape = (height_lr, width_lr, channels))\n",
        "  normalized = inputs / 255\n",
        "  gray = SeparableConv2D(1, 1, padding = 'same', name = 'color_sep')(normalized)\n",
        "  color = normalized - gray\n",
        "\n",
        "  gray = SeparableConv2D(16, kernel_size = 3, padding = 'same', activation = 'relu', name = 'gray_filters')(gray)\n",
        "  #gray = upsample4xGray(gray) #wait for tf2.3-rc0 release\n",
        "  gray = Conv2DTranspose(1, 4, 4, padding = 'same', name = 'gray_upsample')(gray)\n",
        "  #color = UpSampling2D(size = 4, interpolation = 'bilinear')(color) #wait for tf2.3-rc0 release\n",
        "  color = Conv2DTranspose(3, 4, 4, padding = 'same', name = 'color_upsample')(color)\n",
        "  outputs = Add()([color, gray])\n",
        "  outputs = outputs * 255\n",
        "  gray = gray * 255\n",
        "  return Model(inputs = inputs, outputs = [outputs, gray])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5hbFAKdCrtB",
        "colab_type": "text"
      },
      "source": [
        "###define separator callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFBHFNVjCnHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def logging_separator(epoch, logs):\n",
        "  global this_time\n",
        "  if (epoch % 200 == 0) and (epoch > 0):\n",
        "    last_time = this_time\n",
        "    this_time = time.time()\n",
        "      \n",
        "    clear_output()\n",
        "    print('epoch', real_epoch + 1, '/', separator_epochs, '--> step', (epoch), '/200', '| loss:', logs['loss'], '| time taken:', this_time - last_time\n",
        "         )\n",
        "    TFLITE_MODEL = \"superresolution_4x_tflite_convatt_separator.tflite\"\n",
        "    run_model = tf.function(lambda x : separator(x))\n",
        "    concrete_func = run_model.get_concrete_function(tf.TensorSpec(separator.inputs[0].shape, separator.inputs[0].dtype))\n",
        "    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "    #converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "    converted_tflite_model = converter.convert()\n",
        "    open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)\n",
        "    tflite_separator_interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)\n",
        "    testX, testY, testZ = get_batch_separator(1, height_lr, width_lr)\n",
        "    input_details = tflite_separator_interpreter.get_input_details()\n",
        "    output_details = tflite_separator_interpreter.get_output_details()\n",
        "    \n",
        "    tflite_separator_interpreter.allocate_tensors()\n",
        "    tflite_separator_interpreter.set_tensor(input_details[0]['index'], testX.astype(np.float32))\n",
        "    tflite_separator_interpreter.invoke()\n",
        "    predY = tflite_separator_interpreter.get_tensor(output_details[0]['index'])\n",
        "    predZ = tflite_separator_interpreter.get_tensor(output_details[1]['index'])\n",
        "\n",
        "    show([testX[0], testY[0], predY[0], testZ[0], predZ[0]])\n",
        "\n",
        "separator_logging_callback = LambdaCallback(\n",
        "  on_epoch_end = lambda epoch, logs: logging_separator(epoch, logs)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kt5FxCNICxLF",
        "colab_type": "text"
      },
      "source": [
        "###compile separator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39Lhs_eoC31h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  separator = build_separator()\n",
        "  separator.compile(optimizer = Adam(learning_rate), loss = 'mae')\n",
        "  separator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqdTja85C9Vo",
        "colab_type": "text"
      },
      "source": [
        "###train separator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKpXsuBqDDP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "this_time = time.time()\n",
        "print('trying to load last saved weights...', end = ' ') \n",
        "try:\n",
        "  with open(separator_weight_file, 'rb') as file:\n",
        "    separator.set_weights(dill.load(file))\n",
        "  print('success.')\n",
        "except:\n",
        "  print('failed.')\n",
        "\n",
        "X, Y, Z = get_batch_separator(batch_size, height_lr, width_lr)\n",
        "test_loss = separator.evaluate(X, [Y, Z], return_dict = True)\n",
        "if test_loss['loss'] > 20:\n",
        "  for real_epoch in range(separator_epochs):\n",
        "    X, Y, Z = get_batch_separator(batch_size, height_lr, width_lr)\n",
        "    separator.fit(X, [Y, Z], batch_size, epochs = 201, verbose = 0, callbacks = [separator_logging_callback], shuffle = True)\n",
        "        \n",
        "    print('trying to save weights...', end = ' ')\n",
        "    try:\n",
        "      with open(separator_weight_file, 'wb') as file:\n",
        "        dill.dump(separator.get_weights(), file)\n",
        "      print('success.')\n",
        "    except:\n",
        "      print('failed.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpIUl7HiDI5h",
        "colab_type": "text"
      },
      "source": [
        "###save weights for generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTWmZxVlDNGs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "color_sep = separator.get_layer('color_sep').get_weights()\n",
        "gray_filters = separator.get_layer('gray_filters').get_weights()\n",
        "color_upsample = separator.get_layer('color_upsample').get_weights()\n",
        "gray_upsample = separator.get_layer('gray_upsample').get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw1mtqFCTSGS",
        "colab_type": "text"
      },
      "source": [
        "###combined perceptual and L1 loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEw1lCooTfil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "perceptual_model = VGG16(include_top=False, weights='imagenet', input_shape=(height_lr, width_lr, 3)) \n",
        "perceptual_model.summary()\n",
        "\n",
        "def multi_loss(y_true, y_pred): #combination of different losses\n",
        "    true = loss_model(y_true)\n",
        "    pred = loss_model(y_pred)\n",
        "    perceptual_loss = K.mean(K.abs(pred - true))\n",
        "\n",
        "    L1loss = K.mean(K.abs(y_true - y_pred)) # mean absolute error loss\n",
        "\n",
        "    loss = (L1loss + perceptual_loss) / 2\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tncPMspRFm3e",
        "colab_type": "text"
      },
      "source": [
        "### dataset function for generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__E-GekYFqov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# return batch of augmented train and target images with quantity n_samples\n",
        "def get_batch_generator(n_samples, height, width):\n",
        "    # define a ImageGenerator instance from keras with augmentations\n",
        "    image_gen = ImageDataGenerator(rotation_range = 359,\n",
        "                           width_shift_range = 2,\n",
        "                           height_shift_range = 2,\n",
        "                           zoom_range = [0.25, 0.8],\n",
        "                           shear_range = 0.1,\n",
        "                           horizontal_flip = True,\n",
        "                           vertical_flip = True,\n",
        "                           fill_mode = 'reflect',\n",
        "                           data_format = 'channels_last',\n",
        "                           interpolation_order = 5,\n",
        "                           brightness_range = [0.5, 1.5])\n",
        "    #seed for random augmentations\n",
        "    random_seed = int(random.random() * 100000)\n",
        "    #generate augmented images\n",
        "    with silence_stdout():\n",
        "        y_train = image_gen.flow_from_directory('.', \n",
        "                                                target_size = (height * scale, width * scale), \n",
        "                                                batch_size = n_samples, \n",
        "                                                class_mode = None,\n",
        "                                                interpolation = 'lanczos', \n",
        "                                                seed = random_seed)\n",
        "        y_train = y_train.__getitem__(0).copy() #fix for 'array doesn't own its data'\n",
        "        x_train = np.empty((len(y_train), height, width, 3))\n",
        "    for i in range(n_samples):\n",
        "        #random_zoom = random.random() * 2.5 + 2.5 #random blur/zoom between 2.5 and 5\n",
        "        #dummy = resize(x_train[i], (height // random_zoom, width // random_zoom, 3))\n",
        "        #x_train[i] = resize(dummy, (height, width, 3))\n",
        "        x_train[i] = resize(y_train[i], (height, width, 3), order = 5)\n",
        "    \n",
        "    #y_train = np.dot(y_train[...,:3], [0.33, 0.33, 0.33])\n",
        "    return x_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JualJzCkopIc",
        "colab_type": "text"
      },
      "source": [
        "### try to load old batch file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOxk8de6pfbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('trying to load batch file...', end = ' ') \n",
        "!7z x batch.7z.001 -y -scsUTF-8\n",
        "try:\n",
        "    with open(batch_file, 'rb') as file:\n",
        "        [X, Y] = dill.load(file)\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed. building new batch...', end = ' ')\n",
        "    X, Y = get_batch_generator(batch_size, height_lr, width_lr)\n",
        "    print('trying to save new batch...', end = ' ')\n",
        "    try:\n",
        "        with open(batch_file, 'wb') as file:\n",
        "            dill.dump([X, Y], file)\n",
        "            !rm -rf batch.7z.*\n",
        "            !7z -v20m a batch.7z batch -scsUTF-8\n",
        "        print('success.')\n",
        "        try:\n",
        "            print('trying to load batch file...', end = ' ') \n",
        "            with open(batch_file, 'rb') as file:\n",
        "                [X, Y] = dill.load(file)\n",
        "            print('success.')\n",
        "        except:\n",
        "            print('failed.')\n",
        "    except:\n",
        "        print('failed.')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQDa8VL9DiAu",
        "colab_type": "text"
      },
      "source": [
        "### build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NubiVbZTDmFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator():\n",
        "  inputs = Input(shape = (height_lr, width_lr, channels))\n",
        "  normalized = inputs / 255\n",
        "  gray = SeparableConv2D(1, 1, padding = 'same', name = 'color_sep', trainable = False)(normalized)\n",
        "  color = normalized - gray\n",
        "  \n",
        "  gray = SeparableConv2D(16, kernel_size = 3, padding = 'same', activation = 'relu', name = 'gray_filters', trainable = False)(gray)\n",
        "  \n",
        "  for block in range (1):\n",
        "    skip = gray\n",
        "    att = gray = Conv2D(16, 4, activation = 'swish', strides = 1, padding = 'same', name = 'conv1_block' + str(block))(gray)\n",
        "    gray = Conv2D(16, 4, strides = 1, padding = 'same', name = 'conv2_block' + str(block))(gray)\n",
        "    attention = Conv2D(1, 4, activation = 'sigmoid', padding = 'same', name = 'conv3_block' + str(block))(att)\n",
        "    gray = Multiply()([gray, attention])    \n",
        " \n",
        "    gray = Add()([gray, skip])\n",
        "\n",
        "  #gray = upsample4xGray(gray) #wait for tensorflow 2.3.0-rc0\n",
        "  gray = Conv2DTranspose(1, 4, 4, padding = 'same', name = 'gray_upsample')(gray)\n",
        "\n",
        "  #color = UpSampling2D(size = 4, interpolation = 'bilinear')(color) #wait for tensorflow 2.3.0-rc0\n",
        "  color = Conv2DTranspose(3, 4, 4, padding = 'same', name = 'color_upsample')(color)\n",
        "  outputs = Add()([color, gray])\n",
        "  outputs = outputs * 255\n",
        "  return Model(inputs = inputs, outputs = outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJVR2151VyFe",
        "colab_type": "text"
      },
      "source": [
        "###define callback for generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDYpkmbyV0sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loggingGenerator(epoch, logs):\n",
        "  global this_time\n",
        "  if (epoch % logging_steps == 0) and (epoch > 0):\n",
        "    last_time = this_time\n",
        "    this_time = time.time()\n",
        "      \n",
        "    clear_output()\n",
        "    print('epoch', real_epoch + 1, '/', epochs, '--> step', (epoch), '/', steps_per_epoch\n",
        "          , '| loss:', logs['loss'], '| time taken:', this_time - last_time\n",
        "         )\n",
        "    TFLITE_MODEL = \"superresolution_4x_tflite_convatt.tflite\"\n",
        "    run_model = tf.function(lambda x : generator(x))\n",
        "    concrete_func = run_model.get_concrete_function(tf.TensorSpec(generator.inputs[0].shape, generator.inputs[0].dtype))\n",
        "    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "    converted_tflite_model = converter.convert()\n",
        "    open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)\n",
        "    tflite_generator_interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)\n",
        "    testX, testY = get_batch_generator(1, height_lr, width_lr)\n",
        "    input_details = tflite_generator_interpreter.get_input_details()\n",
        "    output_details = tflite_generator_interpreter.get_output_details()\n",
        "    \n",
        "    tflite_generator_interpreter.allocate_tensors()\n",
        "    tflite_generator_interpreter.set_tensor(input_details[0]['index'], testX.astype(np.float32))\n",
        "    tflite_generator_interpreter.invoke()\n",
        "    predY = tflite_generator_interpreter.get_tensor(output_details[0]['index'])\n",
        "    \n",
        "    show([testX[0], testY[0], predY[0]])\n",
        "\n",
        "generator_logging_callback = LambdaCallback(\n",
        "  on_epoch_end = lambda epoch, logs: loggingGenerator(epoch, logs)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwIKZRoEeH2z",
        "colab_type": "text"
      },
      "source": [
        "###compile model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMoMrQxKi8wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  loss_model = Model(inputs=perceptual_model.input, outputs=perceptual_model.get_layer('block2_conv2').output) \n",
        "  generator = build_generator()\n",
        "  generator.compile(optimizer = Adam(learning_rate, beta_1=0.5, beta_2=0.999), loss = multi_loss)\n",
        "#  generator.compile(optimizer = Adam(0.0001, beta_1=0.5, beta_2=0.999), loss = multi_loss)\n",
        "\n",
        "generator.get_layer('color_sep').set_weights(color_sep)\n",
        "generator.get_layer('gray_filters').set_weights(gray_filters)\n",
        "generator.get_layer('color_upsample').set_weights(color_upsample)\n",
        "#generator.get_layer('gray_upsample').set_weights(gray_upsample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYvAdu9TetrQ",
        "colab_type": "text"
      },
      "source": [
        "### load weights and train model\n",
        "repeat this step, until desired quality is reached, try reducing learning rate to 0.00003 after 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2KxW0NJe2GN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "this_time = time.time()\n",
        "print('trying to load last saved generator weights...', end = ' ') \n",
        "try:\n",
        "    with open(generator_weight_file, 'rb') as file:\n",
        "        generator.set_weights(dill.load(file))\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed.')\n",
        "print('trying to load last saved generator optimizer weights...', end = ' ') \n",
        "try:\n",
        "    with open(generator_optimizer_weight_file, 'rb') as file:\n",
        "        generator.optimizer.set_weights(dill.load(file))\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed.')\n",
        "\n",
        "#X, Y = get_batch_generator(batch_size, height_lr, width_lr)\n",
        "for real_epoch in range(epochs):\n",
        "    #X, Y = get_batch_generator(batch_size, height_lr, width_lr)\n",
        "    generator.fit(X, Y, batch_size, epochs = steps_per_epoch + 1, verbose = 0, callbacks = [generator_logging_callback], shuffle = True)\n",
        "    \n",
        "    print('trying to save generator weights...', end = ' ')\n",
        "    try:\n",
        "        with open(generator_weight_file, 'wb') as file:\n",
        "            dill.dump(generator.get_weights(), file)\n",
        "        print('success.')\n",
        "    except:\n",
        "        print('failed.')\n",
        "\n",
        "    print('trying to save generator optimizer weights...', end = ' ')\n",
        "    try:\n",
        "        with open(generator_optimizer_weight_file, 'wb') as file:\n",
        "            dill.dump(generator.optimizer.get_weights(), file)\n",
        "        print('success.')\n",
        "    except:\n",
        "        print('failed.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JlPYA9BGJZV",
        "colab_type": "text"
      },
      "source": [
        "### try several speed and size optimization strategies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LhTbgUvGbC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get layer weights\n",
        "color_sep = generator.get_layer('color_sep').get_weights()\n",
        "gray_filters = generator.get_layer('gray_filters').get_weights()\n",
        "color_upsample = generator.get_layer('color_upsample').get_weights()\n",
        "gray_upsample = generator.get_layer('gray_upsample').get_weights()\n",
        "weights = {}\n",
        "\n",
        "for x in range(15):\n",
        "  weights[\"conv1_block{0}\".format(x)] = generator.get_layer('conv1_block' + str(x)).get_weights()\n",
        "  weights[\"conv2_block{0}\".format(x)] = generator.get_layer('conv2_block' + str(x)).get_weights()\n",
        "  weights[\"conv3_block{0}\".format(x)] = generator.get_layer('conv3_block' + str(x)).get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay3vZybMLVJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator_variation():\n",
        "  inputs = Input(shape = (height_lr, width_lr, channels))\n",
        "  normalized = inputs / 255\n",
        "  gray = SeparableConv2D(1, 1, padding = 'same', name = 'color_sep', trainable = False)(normalized)\n",
        "  color = normalized - gray\n",
        "  \n",
        "  gray = SeparableConv2D(16, kernel_size = 3, padding = 'same', activation = 'relu', name = 'gray_filters', trainable = False)(gray)\n",
        "  \n",
        "  for block in range (13):\n",
        "    skip = gray\n",
        "    att = gray = Conv2D(16, 3, activation = 'swish', strides = 1, padding = 'same', name = 'conv1_block' + str(block))(gray)\n",
        "    gray = Conv2D(16, 3, strides = 1, padding = 'same', name = 'conv2_block' + str(block))(gray)\n",
        "    attention = Conv2D(1, 3, activation = 'sigmoid', padding = 'same', name = 'conv3_block' + str(block))(att)\n",
        "    gray = Multiply()([gray, attention])    \n",
        " \n",
        "    gray = Add()([gray, skip])\n",
        "\n",
        "  #gray = upsample4xGray(gray) #wait for tensorflow 2.3.0-rc0\n",
        "  gray = Conv2DTranspose(1, 4, 4, padding = 'same', name = 'gray_upsample')(gray)\n",
        "\n",
        "  #color = UpSampling2D(size = 4, interpolation = 'bilinear')(color) #wait for tensorflow 2.3.0-rc0\n",
        "  color = Conv2DTranspose(3, 4, 4, padding = 'same', name = 'color_upsample')(color)\n",
        "  outputs = Add()([color, gray])\n",
        "  outputs = outputs * 255\n",
        "  return Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "with strategy.scope():\n",
        "  generator = build_generator_variation()\n",
        "  generator.compile(optimizer = Adam(gen_lr), loss = multi_loss)\n",
        "  generator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWp2nWn4NbtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transfer old weights\n",
        "generator.get_layer('color_sep').set_weights(color_sep)\n",
        "generator.get_layer('gray_filters').set_weights(gray_filters)\n",
        "generator.get_layer('color_upsample').set_weights(color_upsample)\n",
        "generator.get_layer('gray_upsample').set_weights(gray_upsample)\n",
        "\n",
        "for x in range(13):\n",
        "  generator.get_layer('conv1_block' + str(x)).set_weights(weights[\"conv1_block{0}\".format(x)])\n",
        "  generator.get_layer('conv2_block' + str(x)).set_weights(weights[\"conv2_block{0}\".format(x)])\n",
        "  generator.get_layer('conv3_block' + str(x)).set_weights(weights[\"conv3_block{0}\".format(x)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KuM6ocFQwLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train to test\n",
        "for real_epoch in range(epochs):\n",
        "    X, Y = get_batch_generator(batch_size, height_lr, width_lr)\n",
        "    generator.fit(X, Y, batch_size, epochs = steps_per_epoch + 1, verbose = 0, callbacks = [generator_logging_callback], shuffle = True)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLigLCfBX3cV",
        "colab_type": "text"
      },
      "source": [
        "### prune the model for faster inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs4dHEuCgxGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5 #Number of epochs to train\n",
        "steps_per_epoch = 100 #How much iterations per epoch to train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukIWNIyGX8XJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.10,\n",
        "                                                               final_sparsity=0.4,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=epochs)\n",
        "}\n",
        "\n",
        "with strategy.scope():\n",
        "  model_for_pruning = prune_low_magnitude(generator, **pruning_params)\n",
        "  model_for_pruning.compile(optimizer = Adam(gen_lr), loss = multi_loss)\n",
        "  \n",
        "  model_for_pruning.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kaIbjmQa2Q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "this_time = time.time()\n",
        "print('trying to load last saved weights...', end = ' ') \n",
        "try:\n",
        "    with open(pruning_weight_file, 'rb') as file:\n",
        "        model_for_pruning.set_weights(dill.load(file))\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed.')\n",
        "\n",
        "for real_epoch in range(epochs):\n",
        "    X, Y = get_batch_generator(batch_size, height_lr, width_lr)\n",
        "    model_for_pruning.fit(X, Y, batch_size, epochs = steps_per_epoch + 1, verbose = 1, callbacks = [tfmot.sparsity.keras.UpdatePruningStep()], shuffle = True)\n",
        "    clear_output()\n",
        "    print('trying to save weights...', end = ' ')\n",
        "    try:\n",
        "        with open(pruning_weight_file, 'wb') as file:\n",
        "            dill.dump(model_for_pruning.get_weights(), file)\n",
        "        print('success.')\n",
        "    except:\n",
        "        print('failed.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsasAdm1dnuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCAWm7OsyMlu",
        "colab_type": "text"
      },
      "source": [
        "### validate on complete picture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42HOsHFQym1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = Image.open('./DIV2K-sample.png').convert('L')\n",
        "img = np.array(img)\n",
        "img = img.astype(np.float32)\n",
        "\n",
        "print('ground truth:')\n",
        "display_image_in_actual_size(img)\n",
        "\n",
        "#generator = build_generator(img.shape)\n",
        "\n",
        "print('trying to load last saved weights...', end = ' ') \n",
        "try:\n",
        "    with open(weight_file, 'rb') as file:\n",
        "        generator.set_weights(dill.load(file))\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed.')\n",
        "\n",
        "\n",
        "print('superresolution:')\n",
        "predicted = generator.predict(np.expand_dims((img), 0))\n",
        "print(predicted.shape)\n",
        "display_image_in_actual_size(predicted.squeeze(3))\n",
        "predicted = Image.fromarray(predicted.astype(np.uint8))\n",
        "'''\n",
        "print('trying to save image as \\'superresolution_result.png\\'...', end = ' ')\n",
        "try:\n",
        "    predicted.save('superresolution_result.png', \"PNG\")\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed.')\n",
        "    pass\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nU8Llyfa784",
        "colab_type": "text"
      },
      "source": [
        "###export to tensorflow.js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHSEuGzzbBxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator.save('sr_tfjs.h5')\n",
        "!pip install tensorflowjs\n",
        "!tensorflowjs_converter --input_format=keras sr_tfjs.h5 model/\n",
        "!ls -la\n",
        "!zip -r model.zip model \n",
        "print('you can download model.zip from the menu...')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
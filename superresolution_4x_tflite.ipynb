{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "superresolution_4x_tflite.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Y52zwvlpHvCC"
      },
      "source": [
        "## superresolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s-U33BDYHvCF"
      },
      "source": [
        "### options\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bDQFzxuJHvCH",
        "colab": {}
      },
      "source": [
        "normalize = True #if set to True, input and output images will be normalized to [0, 1]\n",
        "separator_epochs = 50\n",
        "epochs = 1000 #Number of epochs to train\n",
        "scale = 4 #How much should we upscale images\n",
        "channels = 3 #channels of low resolution image\n",
        "batch_size = 8 #what batch-size should we use (decrease if you encounter video memory errors)\n",
        "height_lr = 128 #height of low resolution image\n",
        "width_lr = height_lr #width of low resolution image\n",
        "learning_rate = 0.0001 #learning rate\n",
        "logging_steps = epochs // 20 #how often to update the training log\n",
        "discriminator_weight_file = 'sr_4x_discriminator_weights' #name of weight file\n",
        "generator_weight_file = 'sr_4x_generator_weights' #name of weight file\n",
        "separator_weight_file = 'sr_4x_separator_weights' #name of weight file\n",
        "pruning_weight_file = 'sr_4x_pruning_weights' #name of weight file\n",
        "filters = 16 #width of network\n",
        "kernelSize = 3 #kernel size of convolution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GzyzlkF3HvCL"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "v78MsA4CHvCM",
        "colab": {}
      },
      "source": [
        "import os\n",
        "%cd /content\n",
        "!git clone https://github.com/BenjaminWegener/superresolution #download Dataset\n",
        "%cd superresolution\n",
        "#%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "!pip install tensorflow-model-optimization\n",
        "import tensorflow_model_optimization as tfmot\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from math import isnan\n",
        "import random\n",
        "import dill\n",
        "import time\n",
        "from PIL import Image\n",
        "from skimage.transform import resize\n",
        "from contextlib import contextmanager\n",
        "import sys\n",
        "@contextmanager\n",
        "def silence_stdout():\n",
        "    new_target = open(os.devnull, \"w\")\n",
        "    old_target = sys.stdout\n",
        "    sys.stdout = new_target\n",
        "    try:\n",
        "        yield new_target\n",
        "    finally:\n",
        "        sys.stdout = old_target   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WyQf_dwWHvCR"
      },
      "source": [
        "### functions for image visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ygs-7DxwHvCS",
        "colab": {}
      },
      "source": [
        "def show(tensors):\n",
        "    plt.rcParams['figure.figsize'] = [20, 10]\n",
        "    fig = plt.figure()\n",
        "    for i in range(len(tensors)):\n",
        "        cmap = 'gray'\n",
        "        try:\n",
        "            tensors[i] = np.squeeze(tensors[i], axis = 0)\n",
        "        except:\n",
        "            pass\n",
        "        try:\n",
        "            tensors[i] = np.squeeze(tensors[i], axis = 2)\n",
        "        except:\n",
        "            pass\n",
        "        try:    \n",
        "            depth = tensors[i].shape[2]\n",
        "            cmap = None\n",
        "        except:\n",
        "            pass\n",
        "        if normalize:\n",
        "            tensors[i] = tensors[i] * 255\n",
        "        tensors[i] = np.clip(tensors[i], 0, 255)\n",
        "        fig.add_subplot(1, len(tensors), i + 1)\n",
        "        plt.imshow(tensors[i].astype(np.uint8), cmap = cmap, interpolation = 'spline36')\n",
        "        #plt.imshow(tensors[i].astype(np.uint8).squeeze(axis=2), cmap='gray', interpolation = 'spline36')\n",
        "    plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYBDslhEySJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# show image in actual size https://stackoverflow.com/a/42314798/\n",
        "def display_image_in_actual_size(im_data):\n",
        "    try:\n",
        "        im_data = np.squeeze(im_data, axis = 0)\n",
        "    except:\n",
        "        pass \n",
        "    im_data = np.clip(im_data, 0, 255)\n",
        "    dpi = 100\n",
        "    print(im_data.shape)\n",
        "    height = im_data.shape[0]\n",
        "    width = im_data.shape[1]\n",
        "    figsize = width / float(dpi), height / float(dpi)\n",
        "    fig = plt.figure(figsize=figsize)\n",
        "    ax = fig.add_axes([0, 0, 1, 1])\n",
        "    ax.axis('off')\n",
        "    #ax.imshow(im_data.astype(np.uint8), cmap='gray', interpolation = 'spline36')\n",
        "    ax.imshow(im_data.astype(np.uint8), interpolation = 'spline36')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SJi-rBgoHvCU"
      },
      "source": [
        "### dataset function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m5lxEgg6HvCV",
        "colab": {}
      },
      "source": [
        "# return batch of augmented train and target images with quantity n_samples\n",
        "def get_batch_separator(n_samples, height, width):\n",
        "    # define a ImageGenerator instance from keras with augmentations\n",
        "    image_gen = ImageDataGenerator(rotation_range = 359,\n",
        "                           width_shift_range = 2,\n",
        "                           height_shift_range = 2,\n",
        "                           zoom_range = [0.25, 0.8],\n",
        "                           shear_range = 0.1,\n",
        "                           horizontal_flip = True,\n",
        "                           vertical_flip = True,\n",
        "                           fill_mode = 'reflect',\n",
        "                           data_format = 'channels_last',\n",
        "                           interpolation_order = 5,\n",
        "                           brightness_range = [0.5, 1.5])\n",
        "    #seed for random augmentations\n",
        "    random_seed = int(random.random() * 100000)\n",
        "    #generate augmented images\n",
        "    with silence_stdout():\n",
        "        y_train = image_gen.flow_from_directory('.', \n",
        "                                                target_size = (height * scale, width * scale), \n",
        "                                                batch_size = n_samples, \n",
        "                                                class_mode = None,\n",
        "                                                interpolation = 'lanczos', \n",
        "                                                seed = random_seed)\n",
        "        y_train = y_train.__getitem__(0).copy() #fix for 'array doesn't own its data'\n",
        "        x_train = np.empty((len(y_train), height, width, 3))\n",
        "    for i in range(n_samples):\n",
        "        #random_zoom = random.random() * 2.5 + 2.5 #random blur/zoom between 2.5 and 5\n",
        "        #dummy = resize(x_train[i], (height // random_zoom, width // random_zoom, 3))\n",
        "        #x_train[i] = resize(dummy, (height, width, 3))\n",
        "        x_train[i] = resize(y_train[i], (height, width, 3), order = 5)\n",
        "    if normalize:\n",
        "        x_train = x_train / 255\n",
        "        y_train = y_train / 255\n",
        "    z_train = np.dot(y_train[...,:3], [0.33, 0.33, 0.33])\n",
        "    return x_train, y_train, z_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA3TToBjTLTd",
        "colab_type": "text"
      },
      "source": [
        "###initialize tpu backend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erR3p75VTPt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "\n",
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw1mtqFCTSGS",
        "colab_type": "text"
      },
      "source": [
        "###combined perceptual and L1 loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEw1lCooTfil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "perceptual_model = VGG16(include_top=False, weights='imagenet', input_shape=(height_lr, width_lr, 3)) \n",
        "perceptual_model.summary()\n",
        "\n",
        "def multi_loss(y_true, y_pred): #combination of different losses\n",
        "    loss = 1\n",
        "    true = loss_model(y_true)\n",
        "    pred = loss_model(y_pred)\n",
        "\n",
        "    loss += K.mean(K.abs(pred - true)\n",
        "\n",
        "    loss = loss * (K.mean(K.abs(y_true - y_pred)) + 1) # mean absolute error loss\n",
        "\n",
        "    loss = loss - 1\n",
        "    loss = K.clip(loss, 0.00001, 999)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gvy5AbKwHvCi"
      },
      "source": [
        "### build color separation model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SKFcfdh_HvCf",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "def build_separator():\n",
        "  inputs = Input(shape = (height_lr, width_lr, channels))\n",
        "  gray = SeparableConv2D(1, 1, padding = 'same', name = 'color_sep')(inputs)\n",
        "  color = inputs - gray\n",
        "  \n",
        "  gray = SeparableConv2D(16, kernel_size = 3, padding = 'same', activation = 'relu', name = 'gray_filters')(gray)\n",
        "  #gray = upsample4xGray(gray) #wait for tf2.3-rc0 release\n",
        "  gray = Conv2DTranspose(1, 4, 4, padding = 'same', name = 'gray_upsample')(gray)\n",
        "\n",
        "  #color = UpSampling2D(size = 4, interpolation = 'bilinear')(color) #wait for tf2.3-rc0 release\n",
        "  color = Conv2DTranspose(3, 4, 4, padding = 'same', name = 'color_upsample')(color)\n",
        "  outputs = Add()([color, gray])\n",
        "  return Model(inputs = inputs, outputs = [outputs, gray])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EmBC-aMQHvCk"
      },
      "source": [
        "### define calllback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hkYfqMpN2MIQ",
        "scrolled": false,
        "colab": {}
      },
      "source": [
        "def logging_separator(epoch, logs):\n",
        "  global this_time\n",
        "  if (epoch % 200 == 0) and (epoch > 0):\n",
        "    last_time = this_time\n",
        "    this_time = time.time()\n",
        "      \n",
        "    clear_output()\n",
        "    print('epoch', real_epoch + 1, '/', epochs, '--> step', (epoch), '/', steps_per_epoch\n",
        "          , '| loss:', logs['loss'], '| time taken:', this_time - last_time\n",
        "         )\n",
        "    TFLITE_MODEL = \"superresolution.tflite\"\n",
        "    run_model = tf.function(lambda x : separator(x))\n",
        "    concrete_func = run_model.get_concrete_function(tf.TensorSpec(separator.inputs[0].shape, separator.inputs[0].dtype))\n",
        "    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "    #converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "    converted_tflite_model = converter.convert()\n",
        "    open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)\n",
        "    tflite_separator_interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)\n",
        "    testX, testY, testZ = get_batch_separator(1, height_lr, width_lr)\n",
        "    input_details = tflite_separator_interpreter.get_input_details()\n",
        "    output_details = tflite_separator_interpreter.get_output_details()\n",
        "    \n",
        "    tflite_separator_interpreter.allocate_tensors()\n",
        "    tflite_separator_interpreter.set_tensor(input_details[0]['index'], testX.astype(np.float32))\n",
        "    tflite_separator_interpreter.invoke()\n",
        "    predY = tflite_separator_interpreter.get_tensor(output_details[0]['index'])\n",
        "    predZ = tflite_separator_interpreter.get_tensor(output_details[1]['index'])\n",
        "\n",
        "    show([testX[0], testY[0], predY[0], testZ[0], predZ[0]])\n",
        "\n",
        "separator_logging_callback = LambdaCallback(\n",
        "  on_epoch_end = lambda epoch, logs: logging_separator(epoch, logs)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAWc2UKcuUvv",
        "colab_type": "text"
      },
      "source": [
        "### compile separator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVqF5xYUucIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  separator = build_separator()\n",
        "  separator.compile(optimizer = Adam(learning_rate), loss = 'mae')\n",
        "  separator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaB9RCCgwVur",
        "colab_type": "text"
      },
      "source": [
        "### train separator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnKWHvjWwdTy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "this_time = time.time()\n",
        "print('trying to load last saved weights...', end = ' ') \n",
        "try:\n",
        "  with open(separator_weight_file, 'rb') as file:\n",
        "    separator.set_weights(dill.load(file))\n",
        "  print('success.')\n",
        "except:\n",
        "  print('failed.')\n",
        "\n",
        "X, Y, Z = get_batch_separator(batch_size, height_lr, width_lr)\n",
        "test_loss = separator.evaluate(X, [Y, Z], return_dict = True)\n",
        "if test_loss['loss'] > 0.08:\n",
        "  for real_epoch in range(separator_epochs):\n",
        "    X, Y, Z = get_batch_separator(batch_size, height_lr, width_lr)\n",
        "    separator.fit(X, [Y, Z], batch_size, epochs = 200, verbose = 0, callbacks = [separator_logging_callback], shuffle = True)\n",
        "        \n",
        "    print('trying to save weights...', end = ' ')\n",
        "    try:\n",
        "      with open(separator_weight_file, 'wb') as file:\n",
        "        dill.dump(separator.get_weights(), file)\n",
        "      print('success.')\n",
        "    except:\n",
        "      print('failed.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSuV5ID2GbKX",
        "colab_type": "text"
      },
      "source": [
        "### save weights for generator to local variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAn8ZALuGi-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "color_sep = separator.get_layer('color_sep').get_weights()\n",
        "gray_filters = separator.get_layer('gray_filters').get_weights()\n",
        "color_upsample = separator.get_layer('color_upsample').get_weights()\n",
        "gray_upsample = separator.get_layer('gray_upsample').get_weights()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tncPMspRFm3e",
        "colab_type": "text"
      },
      "source": [
        "### dataset function for generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__E-GekYFqov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# return batch of augmented train and target images with quantity n_samples\n",
        "def get_batch_generator(n_samples, height, width):\n",
        "    # define a ImageGenerator instance from keras with augmentations\n",
        "    image_gen = ImageDataGenerator(rotation_range = 359,\n",
        "                           width_shift_range = 2,\n",
        "                           height_shift_range = 2,\n",
        "                           zoom_range = [0.25, 0.8],\n",
        "                           shear_range = 0.1,\n",
        "                           horizontal_flip = True,\n",
        "                           vertical_flip = True,\n",
        "                           fill_mode = 'reflect',\n",
        "                           data_format = 'channels_last',\n",
        "                           interpolation_order = 5,\n",
        "                           brightness_range = [0.5, 1.5])\n",
        "    #seed for random augmentations\n",
        "    random_seed = int(random.random() * 100000)\n",
        "    #generate augmented images\n",
        "    with silence_stdout():\n",
        "        y_train = image_gen.flow_from_directory('.', \n",
        "                                                target_size = (height * scale, width * scale), \n",
        "                                                batch_size = n_samples, \n",
        "                                                class_mode = None,\n",
        "                                                interpolation = 'lanczos', \n",
        "                                                seed = random_seed)\n",
        "        y_train = y_train.__getitem__(0).copy() #fix for 'array doesn't own its data'\n",
        "        x_train = np.empty((len(y_train), height, width, 3))\n",
        "    for i in range(n_samples):\n",
        "        #random_zoom = random.random() * 2.5 + 2.5 #random blur/zoom between 2.5 and 5\n",
        "        #dummy = resize(x_train[i], (height // random_zoom, width // random_zoom, 3))\n",
        "        #x_train[i] = resize(dummy, (height, width, 3))\n",
        "        x_train[i] = resize(y_train[i], (height, width, 3), order = 5)\n",
        "    if normalize:\n",
        "        x_train = x_train / 255\n",
        "        y_train = y_train / 255\n",
        "    #y_train = np.dot(y_train[...,:3], [0.33, 0.33, 0.33])\n",
        "    return x_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQDa8VL9DiAu",
        "colab_type": "text"
      },
      "source": [
        "### build models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NubiVbZTDmFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator():\n",
        "  inputs = Input(shape = (height_lr, width_lr, channels))\n",
        "  gray = SeparableConv2D(1, 1, padding = 'same', name = 'color_sep', trainable = False)(inputs)\n",
        "  color = inputs - gray\n",
        "  \n",
        "  gray = SeparableConv2D(16, kernel_size = 3, padding = 'same', activation = 'relu', name = 'gray_filters', trainable = False)(gray)\n",
        "  \n",
        "  for block in range (30):\n",
        "    skip = gray\n",
        "    #gray = Conv2D(32, 5, activation = 'swish', padding = 'same', strides = 2)(gray)\n",
        "    #gray = Conv2DTranspose(16, 4, padding = 'same', strides = 2)(gray)\n",
        "    gray = Conv2D(16, 3, activation = 'swish', padding = 'same', name = 'conv1_block' + str(block))(gray)\n",
        "    gray = Conv2D(16, 3, padding = 'same', name = 'conv2_block' + str(block))(gray)\n",
        "    attention = GlobalAveragePooling2D()(gray)\n",
        "    attention = Dense(8, activation = 'swish', name = 'dense1_block' + str(block))(attention)\n",
        "    attention = Dense(16, activation = 'sigmoid', name = 'dense2_block' + str(block))(attention)\n",
        "    gray = Multiply()([gray, attention])\n",
        "    gray = Add()([gray, skip])\n",
        "\n",
        "  #gray = upsample4xGray(gray) #wait for tensorflow 2.3.0-rc0\n",
        "  gray = Conv2DTranspose(1, 4, 4, padding = 'same', name = 'gray_upsample')(gray)\n",
        "  #color = UpSampling2D(size = 4, interpolation = 'bilinear')(color) #wait for tensorflow 2.3.0-rc0\n",
        "  color = Conv2DTranspose(3, 4, 4, padding = 'same', name = 'color_upsample')(color)\n",
        "  outputs = Add()([color, gray])\n",
        "  return Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "def build_discriminator():\n",
        "  x = inputs = Input(shape = (height_lr * scale, width_lr * scale, channels))\n",
        "  x = Conv2D(30, 3, activation = 'swish')(x)\n",
        "  x = Conv2D(60, 3, strides = 2, activation = 'swish')(x)\n",
        "  x = Conv2D(120, 3, strides = 2, activation = 'swish')(x)\n",
        "  x = Flatten()(x)\n",
        "  outputs = Dense(units = 1, activation = 'sigmoid')(x)\n",
        "  return Model(inputs = inputs, outputs = outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJVR2151VyFe",
        "colab_type": "text"
      },
      "source": [
        "###define callback for generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDYpkmbyV0sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loggingGenerator(epoch, logs):\n",
        "  global this_time\n",
        "  if (epoch % logging_steps == 0) and (epoch > 0):\n",
        "    last_time = this_time\n",
        "    this_time = time.time()\n",
        "      \n",
        "    clear_output()\n",
        "    print('epoch', real_epoch + 1, '/', epochs, '--> step', (epoch), '/', steps_per_epoch\n",
        "          , '| loss:', logs['loss'], '| time taken:', this_time - last_time\n",
        "         )\n",
        "    TFLITE_MODEL = \"superresolution.tflite\"\n",
        "    run_model = tf.function(lambda x : generator(x))\n",
        "    concrete_func = run_model.get_concrete_function(tf.TensorSpec(separator.inputs[0].shape, generator.inputs[0].dtype))\n",
        "    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "    converted_tflite_model = converter.convert()\n",
        "    open(TFLITE_MODEL, \"wb\").write(converted_tflite_model)\n",
        "    tflite_generator_interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)\n",
        "    testX, testY = get_batch_generator(1, height_lr, width_lr)\n",
        "    input_details = tflite_generator_interpreter.get_input_details()\n",
        "    output_details = tflite_generator_interpreter.get_output_details()\n",
        "    \n",
        "    tflite_generator_interpreter.allocate_tensors()\n",
        "    tflite_generator_interpreter.set_tensor(input_details[0]['index'], testX.astype(np.float32))\n",
        "    tflite_generator_interpreter.invoke()\n",
        "    predY = tflite_generator_interpreter.get_tensor(output_details[0]['index'])\n",
        "    \n",
        "    show([testX[0], testY[0], predY[0]])\n",
        "\n",
        "generator_logging_callback = LambdaCallback(\n",
        "  on_epoch_end = lambda epoch, logs: loggingGenerator(epoch, logs)\n",
        ")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwIKZRoEeH2z",
        "colab_type": "text"
      },
      "source": [
        "### build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMoMrQxKi8wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  loss_model = Model(inputs=perceptual_model.input, outputs=perceptual_model.get_layer('block2_conv2').output) \n",
        "  generator = build_generator()\n",
        "  generator.compile(optimizer = Adam(lr=0.00001, beta_1=0.5, beta_2=0.999), loss = 'mae')\n",
        "\n",
        "generator.get_layer('color_sep').set_weights(color_sep)\n",
        "generator.get_layer('gray_filters').set_weights(gray_filters)\n",
        "generator.get_layer('color_upsample').set_weights(color_upsample)\n",
        "generator.get_layer('gray_upsample').set_weights(gray_upsample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYvAdu9TetrQ",
        "colab_type": "text"
      },
      "source": [
        "### load weights and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2KxW0NJe2GN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "this_time = time.time()\n",
        "print('trying to load last saved weights...', end = ' ') \n",
        "try:\n",
        "    with open(weight_file, 'rb') as file:\n",
        "        generator.set_weights(dill.load(file))\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed.')\n",
        "\n",
        "for real_epoch in range(epochs):\n",
        "    X, Y = get_batch_generator(batch_size, height_lr, width_lr)\n",
        "    generator.fit(X, Y, batch_size, epochs = steps_per_epoch + 1, verbose = 0, callbacks = [generator_logging_callback], shuffle = True)\n",
        "    \n",
        "    print('trying to save weights...', end = ' ')\n",
        "    try:\n",
        "        with open(weight_file, 'wb') as file:\n",
        "            dill.dump(generator.get_weights(), file)\n",
        "        print('success.')\n",
        "    except:\n",
        "        print('failed.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JlPYA9BGJZV",
        "colab_type": "text"
      },
      "source": [
        "### try several speed and size optimization strategies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LhTbgUvGbC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get layer weights\n",
        "color_sep = generator.get_layer('color_sep').get_weights()\n",
        "gray_filters = generator.get_layer('gray_filters').get_weights()\n",
        "color_upsample = generator.get_layer('color_upsample').get_weights()\n",
        "gray_upsample = generator.get_layer('gray_upsample').get_weights()\n",
        "weights = {}\n",
        "\n",
        "for x in range(30):\n",
        "  weights[\"conv1_block{0}\".format(x)] = generator.get_layer('conv1_block' + str(x)).get_weights()\n",
        "  weights[\"conv2_block{0}\".format(x)] = generator.get_layer('conv2_block' + str(x)).get_weights()\n",
        "  weights[\"dense1_block{0}\".format(x)] = generator.get_layer('dense1_block' + str(x)).get_weights()\n",
        "  weights[\"dense2_block{0}\".format(x)] = generator.get_layer('dense2_block' + str(x)).get_weights() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ay3vZybMLVJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#build varia√Ωqa \n",
        "weftion model\n",
        "def buildGeneratorVariation():\n",
        "  inputs = Input(shape = (height_lr, width_lr, channels))\n",
        "  gray = SeparableConv2D(1, 1, padding = 'same', name = 'color_sep', trainable = False)(inputs)\n",
        "  color = inputs - gray\n",
        "  \n",
        "  gray = SeparableConv2D(16, kernel_size = 3, padding = 'same', activation = 'relu', name = 'gray_filters', trainable = False)(gray)\n",
        "  \n",
        "  for block in range (30):\n",
        "    skip = gray\n",
        "    #gray = Conv2D(32, 5, activation = 'swish', padding = 'same', strides = 2)(gray)\n",
        "    #gray = Conv2DTranspose(16, 4, padding = 'same', strides = 2)(gray)\n",
        "    gray = DepthwiseConv2D(3, activation = 'swish', padding = 'same', name = 'conv1_block' + str(block))(gray)\n",
        "    gray = Conv2D(16, 3, padding = 'same', name = 'conv2_block' + str(block), trainable = False)(gray)\n",
        "    attention = GlobalAveragePooling2D()(gray)\n",
        "    attention = Dense(8, activation = 'swish', name = 'dense1_block' + str(block), trainable = False)(attention)\n",
        "    attention = Dense(16, activation = 'sigmoid', name = 'dense2_block' + str(block), trainable = False)(attention)\n",
        "    gray = Multiply()([gray, attention])\n",
        "    gray = Add()([gray, skip])\n",
        "\n",
        "  #gray = upsample4xGray(gray) #wait for tensorflow 2.3.0-rc0\n",
        "  gray = Conv2DTranspose(1, 4, 4, padding = 'same', name = 'gray_upsample', trainable = False)(gray)\n",
        "  #color = UpSampling2D(size = 4, interpolation = 'bilinear')(color) #wait for tensorflow 2.3.0-rc0\n",
        "  color = Conv2DTranspose(3, 4, 4, padding = 'same', name = 'color_upsample', trainable = False)(color)\n",
        "  outputs = Add()([color, gray])\n",
        "  return Model(inputs = inputs, outputs = outputs)\n",
        "\n",
        "with strategy.scope():\n",
        "  generator = buildGeneratorVariation()\n",
        "  generator.compile(optimizer = Adam(gen_lr), loss = multi_loss)\n",
        "  generator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWp2nWn4NbtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#transfer old weights\n",
        "generator.get_layer('color_sep').set_weights(color_sep)\n",
        "generator.get_layer('gray_filters').set_weights(gray_filters)\n",
        "generator.get_layer('color_upsample').set_weights(color_upsample)\n",
        "generator.get_layer('gray_upsample').set_weights(gray_upsample)\n",
        "\n",
        "for x in range(30):\n",
        "  #generator.get_layer('conv1_block' + str(x)).set_weights(weights[\"conv1_block{0}\".format(x)])\n",
        "  generator.get_layer('conv2_block' + str(x)).set_weights(weights[\"conv2_block{0}\".format(x)])\n",
        "  generator.get_layer('dense1_block' + str(x)).set_weights(weights[\"dense1_block{0}\".format(x)])\n",
        "  generator.get_layer('dense2_block' + str(x)).set_weights(weights[\"dense2_block{0}\".format(x)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KuM6ocFQwLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train to test\n",
        "for real_epoch in range(epochs):\n",
        "    X, Y = get_batch_generator(batch_size, height_lr, width_lr)\n",
        "    generator.fit(X, Y, batch_size, epochs = steps_per_epoch + 1, verbose = 0, callbacks = [generator_logging_callback], shuffle = True)\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLigLCfBX3cV",
        "colab_type": "text"
      },
      "source": [
        "### prune the model for faster inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs4dHEuCgxGE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 5 #Number of epochs to train\n",
        "steps_per_epoch = 100 #How much iterations per epoch to train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukIWNIyGX8XJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
        "                                                               final_sparsity=0.80,\n",
        "                                                               begin_step=0,\n",
        "                                                               end_step=epochs)\n",
        "}\n",
        "\n",
        "with strategy.scope():\n",
        "  model_for_pruning = prune_low_magnitude(generator, **pruning_params)\n",
        "  model_for_pruning.compile(optimizer = Adam(gen_lr), loss = multi_loss)\n",
        "  \n",
        "  model_for_pruning.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kaIbjmQa2Q2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "this_time = time.time()\n",
        "print('trying to load last saved weights...', end = ' ') \n",
        "try:\n",
        "    with open(pruning_weight_file, 'rb') as file:\n",
        "        model_for_pruning.set_weights(dill.load(file))\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed.')\n",
        "\n",
        "for real_epoch in range(epochs):\n",
        "    X, Y = get_batch_generator(batch_size, height_lr, width_lr)\n",
        "    model_for_pruning.fit(X, Y, batch_size, epochs = steps_per_epoch + 1, verbose = 1, callbacks = [tfmot.sparsity.keras.UpdatePruningStep()], shuffle = True)\n",
        "    clear_output()\n",
        "    print('trying to save weights...', end = ' ')\n",
        "    try:\n",
        "        with open(pruning_weight_file, 'wb') as file:\n",
        "            dill.dump(model_for_pruning.get_weights(), file)\n",
        "        print('success.')\n",
        "    except:\n",
        "        print('failed.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsasAdm1dnuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCAWm7OsyMlu",
        "colab_type": "text"
      },
      "source": [
        "### validate on complete picture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42HOsHFQym1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = Image.open('./DIV2K-sample.png').convert('L')\n",
        "img = np.array(img)\n",
        "img = img.astype(np.float32)\n",
        "\n",
        "print('ground truth:')\n",
        "display_image_in_actual_size(img)\n",
        "\n",
        "#generator = build_generator(img.shape)\n",
        "\n",
        "print('trying to load last saved weights...', end = ' ') \n",
        "try:\n",
        "    with open(weight_file, 'rb') as file:\n",
        "        generator.set_weights(dill.load(file))\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed.')\n",
        "\n",
        "\n",
        "print('superresolution:')\n",
        "predicted = generator.predict(np.expand_dims((img), 0))\n",
        "print(predicted.shape)\n",
        "display_image_in_actual_size(predicted.squeeze(3))\n",
        "predicted = Image.fromarray(predicted.astype(np.uint8))\n",
        "'''\n",
        "print('trying to save image as \\'superresolution_result.png\\'...', end = ' ')\n",
        "try:\n",
        "    predicted.save('superresolution_result.png', \"PNG\")\n",
        "    print('success.')\n",
        "except:\n",
        "    print('failed.')\n",
        "    pass\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nU8Llyfa784",
        "colab_type": "text"
      },
      "source": [
        "###export to tensorflow.js"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHSEuGzzbBxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator.save('sr_tfjs.h5')\n",
        "!pip install tensorflowjs\n",
        "!tensorflowjs_converter --input_format=keras sr_tfjs.h5 model/\n",
        "!ls -la\n",
        "!zip -r model.zip model \n",
        "print('you can download model.zip from the menu...')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}